{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edfe1206-66cd-4976-952c-b3b105f4563e",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e45906-72db-4b2c-953d-ed169b94c909",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78183f72-5e72-4b3a-af21-13a98237952e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage import filters, color\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import rsatoolbox\n",
    "from rsatoolbox.data import Dataset\n",
    "from rsatoolbox.rdm import calc_rdm\n",
    "from scipy.spatial.distance import cosine\n",
    "from scipy.stats import spearmanr, t\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from cliffs_delta import cliffs_delta\n",
    "from sklearn.preprocessing import normalize\n",
    "from bisect import bisect_right, bisect_left\n",
    "from scipy.spatial.distance import pdist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecf3f34-e4ef-49f8-a401-5e90b74a0a1e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9501201d-9595-4882-bd2b-2f26088ee404",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"conch\", \"plip\", \"prov\", \"quiltnet\", \"resnet\", \"uni\", \"virchow\", \"keep\", \"musk\"]\n",
    "model_tags = ['CONCH', 'PLIP', 'Prov-Gigapath', 'QuiltNet', 'ResNet50', 'UNI', 'Virchow', 'KEEP','MUSK']\n",
    "display_names = model_tags\n",
    "subtypes = ['brca', 'coad', 'luad', 'lusc']\n",
    "num_slides = 50\n",
    "num_patches = 50\n",
    "n_batches = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acdaf5a-08b4-4fa0-b7b4-5e3a6987a56f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Splitting Into 5 Batches of 50 slides/50 patches each for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96690212-a29e-41d7-852c-82bf69410f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"/lotterlab/users/vmishra/\"\n",
    "output_dir = \"/lotterlab/users/vmishra/batched_embeddings_normalized\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "slides_per_batch = num_slides\n",
    "patches_per_slide = num_patches\n",
    "\n",
    "for subtype in subtypes:\n",
    "    for model in models:\n",
    "        file_path = os.path.join(base_path, f\"{subtype}_embeddings_{model}_normalized.npy\")\n",
    "        print(f\"Processing {file_path}...\")\n",
    "\n",
    "        embeddings = np.load(file_path)\n",
    "        num_total = 250 * 250\n",
    "        embedding_dim = embeddings.shape[1]\n",
    "        assert embeddings.shape[0] == num_total, f\"Unexpected shape for {file_path}\"\n",
    "\n",
    "        embeddings = embeddings.reshape(250, 250, embedding_dim)\n",
    "\n",
    "        for batch_idx in range(5):\n",
    "            start_slide = batch_idx * slides_per_batch\n",
    "            end_slide = (batch_idx + 1) * slides_per_batch\n",
    "\n",
    "            batch = embeddings[start_slide:end_slide, :patches_per_slide, :]\n",
    "            batch = batch.reshape(-1, embedding_dim)\n",
    "\n",
    "            batch_filename = f\"{subtype}_{model}_batch{batch_idx+1}_normalized.npy\"\n",
    "            batch_path = os.path.join(output_dir, batch_filename)\n",
    "            np.save(batch_path, batch)\n",
    "            print(f\"Saved batch {batch_idx+1} to {batch_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39a8674-c7ea-4f25-8761-9139d79271ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"/lotterlab/users/vmishra/batched_embeddings_normalized\"\n",
    "rdm_output_dir = \"/lotterlab/users/vmishra/rdms_normalized\"\n",
    "os.makedirs(rdm_output_dir, exist_ok=True)\n",
    "\n",
    "for model in models:\n",
    "    for batch_idx in range(1, n_batches + 1):\n",
    "        print(f\"Processing RDM for model: {model}, batch: {batch_idx}\")\n",
    "\n",
    "        embeddings_list = []\n",
    "        labels = []\n",
    "\n",
    "        for subtype in subtypes:\n",
    "            file_path = os.path.join(input_dir, f\"{subtype}_{model}_batch{batch_idx}_normalized.npy\")\n",
    "            if not os.path.exists(file_path):\n",
    "                print(f\"File not found: {file_path}, skipping.\")\n",
    "                continue\n",
    "\n",
    "            emb = np.load(file_path)\n",
    "            embeddings_list.append(emb)\n",
    "            labels.extend([subtype.upper()] * len(emb))\n",
    "\n",
    "        if len(embeddings_list) < 4:\n",
    "            print(f\"Missing data for model {model}, batch {batch_idx}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        embeddings = np.concatenate(embeddings_list, axis=0)\n",
    "\n",
    "        dataset = Dataset(measurements=embeddings, obs_descriptors={'disease': labels})\n",
    "        rdm = calc_rdm(dataset, method='euclidean')\n",
    "        rdm_matrix = rdm.get_matrices()[0]\n",
    "\n",
    "        save_path = os.path.join(rdm_output_dir, f\"rdm_matrix_{model}_batch{batch_idx}_normalized.npy\")\n",
    "        np.save(save_path, rdm_matrix)\n",
    "        print(f\"Saved RDM to {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950a7ad1-da00-47be-b3d0-8fdbc99edf25",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# RDMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7647284a-7e88-4539-88e9-c62ea68450fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plot(rdm, model_name):\n",
    "    n = rdm.shape[0] / 4\n",
    "    divider_positions = [n, 2*n, 3*n]\n",
    "    diseases = [\"BRCA\", \"COAD\", \"LUAD\", \"LUSC\"]\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    ax = sns.heatmap(rdm, cmap='Blues', annot=False, cbar=True)\n",
    "    ax.collections[0].colorbar.set_label(\"Normalized Distance\", fontsize=12)\n",
    "    plt.title(model_name, fontweight='bold', fontsize=20)\n",
    "    plt.xticks([n // 2, n + n // 2, n + n + n // 2, n + n + n + n // 2],\n",
    "               diseases, rotation=0, ha='center', fontsize=12, fontweight='bold')\n",
    "    plt.yticks([n // 2, n + n // 2, n + n + n // 2, n + n + n + n // 2],\n",
    "               diseases, rotation=0, fontsize=12, fontweight='bold')\n",
    "\n",
    "    # Add divider lines between disease types\n",
    "    for pos in divider_positions:\n",
    "        ax.axhline(pos, color='black', linewidth=1.5)\n",
    "        ax.axvline(pos, color='black', linewidth=1.5)\n",
    "\n",
    "    plt.savefig(\"rdm_matrixv2_normalized-\" + model_name + \".png\", dpi=300, bbox_inches='tight')\n",
    "\n",
    "for m, t in zip(models, model_tags):\n",
    "    print(m)\n",
    "    rdm_mat = np.load(\"/lotterlab/users/vmishra/rdms_normalized/rdm_matrix_\" + m + \"_batch1_normalized.npy\")\n",
    "    rdm_mat = rdm_mat / rdm_mat.max()\n",
    "    make_plot(rdm_mat, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9562685-6a78-4585-b71b-73e2c8aa685d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Spearman and Cosine Similarity Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22fd174-12cd-4e3c-999c-3443404d4374",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_models = len(models)\n",
    "rdm_dir = \"/lotterlab/users/vmishra/rdms_normalized\"\n",
    "\n",
    "cosine_mean = np.zeros((n_models, n_models))\n",
    "cosine_ci_lower = np.zeros((n_models, n_models))\n",
    "cosine_ci_upper = np.zeros((n_models, n_models))\n",
    "\n",
    "spearman_mean = np.zeros((n_models, n_models))\n",
    "spearman_ci_lower = np.zeros((n_models, n_models))\n",
    "spearman_ci_upper = np.zeros((n_models, n_models))\n",
    "\n",
    "def get_range(values):\n",
    "    return np.mean(values), np.min(values), np.max(values)\n",
    "\n",
    "for i, model_i in enumerate(models):\n",
    "    for j, model_j in enumerate(models):\n",
    "        cosine_vals = []\n",
    "        spearman_vals = []\n",
    "\n",
    "        for batch in range(1, n_batches + 1):\n",
    "            path_i = os.path.join(rdm_dir, f\"rdm_matrix_{model_i}_batch{batch}_normalized.npy\")\n",
    "            path_j = os.path.join(rdm_dir, f\"rdm_matrix_{model_j}_batch{batch}_normalized.npy\")\n",
    "            rdm_i = np.load(path_i)\n",
    "            rdm_j = np.load(path_j)\n",
    "\n",
    "            tri_i = rdm_i[np.triu_indices_from(rdm_i, k=1)]\n",
    "            tri_j = rdm_j[np.triu_indices_from(rdm_j, k=1)]\n",
    "\n",
    "            cos_sim = 1 - cosine(tri_i, tri_j)\n",
    "            spearman_corr, _ = spearmanr(tri_i, tri_j)\n",
    "\n",
    "            cosine_vals.append(cos_sim)\n",
    "            spearman_vals.append(spearman_corr)\n",
    "\n",
    "        # Cosine\n",
    "        mean_cos, ci_cos_low, ci_cos_high = get_range(cosine_vals)\n",
    "        cosine_mean[i, j] = mean_cos\n",
    "        cosine_ci_lower[i, j] = ci_cos_low\n",
    "        cosine_ci_upper[i, j] = ci_cos_high\n",
    "\n",
    "        # Spearman\n",
    "        mean_spear, ci_spear_low, ci_spear_high = get_range(spearman_vals)\n",
    "        spearman_mean[i, j] = mean_spear\n",
    "        spearman_ci_lower[i, j] = ci_spear_low\n",
    "        spearman_ci_upper[i, j] = ci_spear_high\n",
    "\n",
    "# Desired model order and display names\n",
    "desired_order = ['uni', 'virchow', 'prov', 'conch', 'plip', 'quiltnet', 'keep', 'musk', 'resnet']\n",
    "display_names = ['UNI', 'Virchow', 'Prov-GigaPath', 'CONCH', 'PLIP', 'QuiltNet', 'KEEP', 'MUSK', 'ResNet-50']\n",
    "reorder_idx = [models.index(m) for m in desired_order]\n",
    "\n",
    "# Reorder all matrices\n",
    "cosine_mean_r = cosine_mean[reorder_idx, :][:, reorder_idx]\n",
    "cosine_ci_lower_r = cosine_ci_lower[reorder_idx, :][:, reorder_idx]\n",
    "cosine_ci_upper_r = cosine_ci_upper[reorder_idx, :][:, reorder_idx]\n",
    "\n",
    "spearman_mean_r = spearman_mean[reorder_idx, :][:, reorder_idx]\n",
    "spearman_ci_lower_r = spearman_ci_lower[reorder_idx, :][:, reorder_idx]\n",
    "spearman_ci_upper_r = spearman_ci_upper[reorder_idx, :][:, reorder_idx]\n",
    "\n",
    "def format_annot(mean_mat, lower_mat, upper_mat):\n",
    "    n = mean_mat.shape[0]\n",
    "    annot = np.empty((n, n), dtype=object)\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            m = mean_mat[i, j]\n",
    "            l = lower_mat[i, j]\n",
    "            u = upper_mat[i, j]\n",
    "            annot[i, j] = f\"{m:.3f}\\n[{l:.3f}–{u:.3f}]\"\n",
    "    return annot\n",
    "\n",
    "cosine_annot = format_annot(cosine_mean_r, cosine_ci_lower_r, cosine_ci_upper_r)\n",
    "spearman_annot = format_annot(spearman_mean_r, spearman_ci_lower_r, spearman_ci_upper_r)\n",
    "\n",
    "# Plot cosine similarity\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cosine_mean_r, annot=cosine_annot, fmt=\"\", xticklabels=display_names, yticklabels=display_names,\n",
    "            cmap=\"Reds\", vmin=0.85, vmax=1, cbar_kws={\"label\": \"Cosine Similarity\"})\n",
    "plt.title(\"Cosine Similarity Between Model RDMs (Normalized)\\nMean [Range Across 5 Batches]\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"cosineHeatmap_normalized.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "# Plot Spearman correlation\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(spearman_mean_r, annot=spearman_annot, fmt=\"\", xticklabels=display_names, yticklabels=display_names,\n",
    "            cmap=\"Reds\", vmin=0, vmax=1, cbar_kws={\"label\": \"Spearman Correlation\"})\n",
    "plt.title(\"Spearman Correlation Between Model RDMs (Normalized)\\nMean [Range Across 5 Batches]\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"spearmanHeatmap_normalized.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e16b76-c41b-4dff-bd8e-fe73fcca8b97",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Mean Spearman correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3caa6796-d9a7-4374-9eca-1f757a8ee782",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_models = len(display_names)\n",
    "\n",
    "average_spearman_corr = (np.sum(spearman_mean_r, axis=1) - np.diag(spearman_mean_r)) / (n_models - 1)\n",
    "\n",
    "df_similarity = pd.DataFrame({\n",
    "    \"Model\": display_names,\n",
    "    \"Average Spearman Correlation\": average_spearman_corr\n",
    "})\n",
    "\n",
    "df_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7169f1f-04f5-4160-8052-6fcf2486502e",
   "metadata": {},
   "source": [
    "# Dendrograms (Change when above values are run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e398795-997e-4f95-9ce1-646b7e1bc1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_models = len(models)\n",
    "spearman_mean = np.ones((n_models, n_models))\n",
    "\n",
    "spearman_mean[0, 1:] = [0.279, 0.41, 0.4, 0.223, 0.195, 0.122]\n",
    "spearman_mean[1, 2:] = [0.466, 0.391, 0.43, 0.371, 0.136]\n",
    "spearman_mean[2, 3:] = [0.505, 0.54, 0.515, 0.181]\n",
    "spearman_mean[3, 4:] = [0.485, 0.734, 0.222]\n",
    "spearman_mean[4, 5:] = [0.384, 0.151]\n",
    "spearman_mean[5, 6] = 0.192\n",
    "\n",
    "for i in range(1, n_models):\n",
    "    for j in range(i):\n",
    "        spearman_mean[i, j] = spearman_mean[j, i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e92d88-7e38-4fd6-9ce5-b6b07d6ab5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "spearman_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54f7b54-d08e-41e3-8d34-74ae1f2b341e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spearman_distances = 1 - spearman_mean\n",
    "\n",
    "# Convert to condensed form\n",
    "spearman_condensed = squareform(spearman_distances, checks=False)\n",
    "\n",
    "# Hierarchical Clustering (Ward's method)\n",
    "linkage_spearman = linkage(spearman_condensed, method=\"ward\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d45558-1039-4894-8eff-166fa887bd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [0.1, 0.33, 0.55, 0.62, 0.70, 0.81, 1.00]\n",
    "\n",
    "# Get Seaborn color palette with one more color than thresholds\n",
    "colors = sns.color_palette(\"deep\", len(thresholds) + 1)\n",
    "colors = ['blue', 'orange', 'green', 'red', 'purple', 'brown', 'gray']\n",
    "\n",
    "# Custom link color function based on thresholds\n",
    "def link_color_func(link_id):\n",
    "    print(link_id)\n",
    "    #print(link_id)\n",
    "#     if link_id < linkage_spearman.shape[0]:\n",
    "#         print(link_id)\n",
    "    row = link_id - linkage_spearman.shape[0] - 1\n",
    "    dist = linkage_spearman[row, 2]  # height of the node\n",
    "    for i, t in enumerate(thresholds):\n",
    "        if dist < t:\n",
    "            return colors[i]\n",
    "    return colors[-1]\n",
    "#     else:\n",
    "#         return 'black'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f68e884-b87e-42d9-953b-f7b284694aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "#plt.figure(figsize=(10, 5))\n",
    "ct = [1, ]\n",
    "dendrogram(linkage_spearman, labels=models, leaf_rotation=90, leaf_font_size=12, color_threshold=0.82) #, link_color_func=link_color_func)\n",
    "plt.title(\"Hierarchical Clustering of Model RDM Similarity (Normalized)\", fontweight='bold')\n",
    "#plt.xlabel(\"Models\")\n",
    "plt.ylabel(\"Distance\")\n",
    "plt.tight_layout()\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.ylabel('Ward Distance', fontsize=12) #, fontweight='bold')\n",
    "\n",
    "plt.savefig('ClusteringSpearman_normalized_v2.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea30a2e4-cdc6-4ae4-bdee-7e14d0f98892",
   "metadata": {},
   "outputs": [],
   "source": [
    "linkage_spearman.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221e7aec-cbaf-48a3-8e2d-0794e80226a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "linkage_spearman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9351b1-4ce3-475f-88b5-e040ba6c0c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae735688-755e-4f9b-97ed-801386cbf5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d45b38-630c-413e-9b18-f3a3fea7f7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"UNI\", \"Virchow\", \"Prov-GigaPath\", \"CONCH\", \"PLIP\", \"QuiltNet\", \"ResNet50\"]\n",
    "# just copied from plot since taking so long\n",
    "n_models = len(models)\n",
    "cosine_mean = np.ones((n_models, n_models))\n",
    "\n",
    "cosine_mean[0, 1:] = [0.939, 0.966, 0.946, 0.924, 0.922, 0.883]\n",
    "cosine_mean[1, 2:] = [0.964, 0.942, 0.936, 0.933, 0.879]\n",
    "cosine_mean[2, 3:] = [0.963, 0.957, 0.958, 0.905]\n",
    "cosine_mean[3, 4:] = [0.947, 0.937, 0.88]\n",
    "cosine_mean[4, 5:] = [0.972, 0.882]\n",
    "cosine_mean[5, 6] = 0.878\n",
    "\n",
    "for i in range(1, n_models):\n",
    "    for j in range(i):\n",
    "        cosine_mean[i, j] = cosine_mean[j, i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea66bab-79ef-4666-9657-3b242ea86c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be24901-66f8-4108-a223-d9c896ce79b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_distances = 1 - cosine_mean\n",
    "\n",
    "# Convert to condensed form\n",
    "cosine_condensed = squareform(cosine_distances, checks=False)\n",
    "\n",
    "# Hierarchical Clustering (Ward's method)\n",
    "linkage_cosine = linkage(cosine_condensed, method=\"ward\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a6b6d7-dfad-4b6c-8521-92a898439ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "#plt.figure(figsize=(10, 5))\n",
    "ct = [1, ]\n",
    "dendrogram(linkage_cosine, labels=models, leaf_rotation=90, leaf_font_size=12, color_threshold=0.14) #, link_color_func=link_color_func)\n",
    "plt.title(\"Hierarchical Clustering of Model RDM Similarity (Normalized)\", fontweight='bold')\n",
    "#plt.xlabel(\"Models\")\n",
    "plt.ylabel(\"Distance\")\n",
    "plt.tight_layout()\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.ylabel('Ward Distance', fontsize=12) #, fontweight='bold')\n",
    "\n",
    "plt.savefig('ClusteringCosine_normalized_v2.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f176bdce-d5e0-45e4-86b5-06e87911ff44",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Slide Specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11dfa239-1a34-461b-82cc-75770f83720d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dir = \"/lotterlab/users/vmishra/batched_embeddings_normalized\"\n",
    "def calculate_distances(embeddings, num_slides, patches_per_slide):\n",
    "    intra_distances = []\n",
    "    inter_distances = []\n",
    "\n",
    "    for slide_idx in range(num_slides):\n",
    "        slide_indices = np.arange(slide_idx * patches_per_slide, (slide_idx + 1) * patches_per_slide)\n",
    "        other_indices = np.setdiff1d(np.arange(embeddings.shape[0]), slide_indices)\n",
    "\n",
    "        slide_distances = pdist(embeddings[slide_indices], metric='euclidean')\n",
    "        intra_distances.extend(slide_distances)\n",
    "\n",
    "        for other_idx in other_indices:\n",
    "            inter_distances.extend(np.linalg.norm(embeddings[slide_indices] - embeddings[other_idx], axis=1))\n",
    "\n",
    "    return np.array(intra_distances), np.array(inter_distances)\n",
    "\n",
    "def efficient_cliffs_delta(a, b):\n",
    "    a = np.sort(a)\n",
    "    b = np.sort(b)\n",
    "    m, n = len(a), len(b)\n",
    "    more = sum(bisect_right(b, x) for x in a)\n",
    "    less = sum(n - bisect_left(b, x) for x in a)\n",
    "    delta = (more - less) / (m * n)\n",
    "    return delta\n",
    "\n",
    "results = []\n",
    "\n",
    "for model in tqdm(models, desc=\"Processing models\"):\n",
    "    delta_vals = []\n",
    "\n",
    "    for batch in range(1, n_batches + 1):\n",
    "        embeddings_list = []\n",
    "        for subtype in subtypes:\n",
    "            file_path = os.path.join(embedding_dir, f\"{subtype}_{model}_batch{batch}_normalized.npy\")\n",
    "            emb = np.load(file_path)\n",
    "            embeddings_list.append(emb)\n",
    "\n",
    "        all_embeddings = np.vstack(embeddings_list)\n",
    "        intra, inter = calculate_distances(all_embeddings, num_slides=num_slides * 4, patches_per_slide=patches_per_slide)\n",
    "\n",
    "        delta_vals.append(efficient_cliffs_delta(intra, inter))\n",
    "\n",
    "    delta_vals = np.array(delta_vals)\n",
    "\n",
    "    results.append({\n",
    "        \"model\": model,\n",
    "        \"display_name\": display_names[models.index(model)],\n",
    "        \"cliffs_delta_mean\": delta_vals.mean(),\n",
    "        \"cliffs_delta_min\": delta_vals.min(),\n",
    "        \"cliffs_delta_max\": delta_vals.max()\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values(by=\"cliffs_delta_mean\", ascending=False).reset_index(drop=True)\n",
    "results_df.to_csv(\"slide_specificity_normalized.csv\", index=False)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc60a30f-83f5-43d8-8f88-12831f6ee8d1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Disease Specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f22f1de-75c9-4df9-8964-41876863a80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dir = \"/lotterlab/users/vmishra/batched_embeddings_normalized\"\n",
    "def efficient_cliffs_delta(a, b):\n",
    "    a = np.sort(a)\n",
    "    b = np.sort(b)\n",
    "    m, n = len(a), len(b)\n",
    "    more = sum(bisect_right(b, x) for x in a)\n",
    "    less = sum(n - bisect_left(b, x) for x in a)\n",
    "    delta = (more - less) / (m * n)\n",
    "    return delta\n",
    "\n",
    "results = []\n",
    "\n",
    "for model in tqdm(models, desc=\"Processing models\"):\n",
    "    delta_vals = []\n",
    "\n",
    "    for batch in range(1, n_batches + 1):\n",
    "        disease_embeddings = {}\n",
    "        for subtype in subtypes:\n",
    "            file_path = os.path.join(embedding_dir, f\"{subtype}_{model}_batch{batch}_normalized.npy\")\n",
    "            disease_embeddings[subtype] = np.load(file_path)\n",
    "\n",
    "        intra_distances = []\n",
    "        for subtype in subtypes:\n",
    "            emb = disease_embeddings[subtype]\n",
    "            dists = pdist(emb, metric='euclidean')\n",
    "            intra_distances.extend(dists)\n",
    "\n",
    "        inter_distances = []\n",
    "        for i in range(len(subtypes)):\n",
    "            for j in range(i + 1, len(subtypes)):\n",
    "                emb1 = disease_embeddings[subtypes[i]]\n",
    "                emb2 = disease_embeddings[subtypes[j]]\n",
    "                diffs = np.linalg.norm(emb1[:, None, :] - emb2[None, :, :], axis=2).flatten()\n",
    "                inter_distances.extend(diffs)\n",
    "\n",
    "        intra = np.array(intra_distances)\n",
    "        inter = np.array(inter_distances)\n",
    "\n",
    "        delta_vals.append(efficient_cliffs_delta(intra, inter))\n",
    "\n",
    "    delta_vals = np.array(delta_vals)\n",
    "\n",
    "    results.append({\n",
    "        \"model\": model,\n",
    "        \"display_name\": display_names[models.index(model)],\n",
    "        \"cliffs_delta_mean\": delta_vals.mean(),\n",
    "        \"cliffs_delta_min\": delta_vals.min(),\n",
    "        \"cliffs_delta_max\": delta_vals.max()\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values(by=\"cliffs_delta_mean\", ascending=False).reset_index(drop=True)\n",
    "results_df.to_csv(\"disease_specificity_normalized.csv\", index=False)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42663596-1e5c-455d-b5be-37302c6c142d",
   "metadata": {},
   "source": [
    "# Spectral Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3ea52d-e1bc-4c83-9d90-b01dd54d9c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"UNI\", \"Virchow\", \"Prov-GigaPath\", \"CONCH\", \"PLIP\", \"QuiltNet\", \"KEEP\", \"MUSK\", \"ResNet-50\"]\n",
    "model_file_keys = {\n",
    "    \"UNI\": \"uni\",\n",
    "    \"Virchow\": \"virchow\",\n",
    "    \"Prov-GigaPath\": \"prov\",\n",
    "    \"CONCH\": \"conch\",\n",
    "    \"PLIP\": \"plip\",\n",
    "    \"QuiltNet\": \"quiltnet\",\n",
    "    \"KEEP\": \"keep\",\n",
    "    \"MUSK\": \"musk\",\n",
    "    \"ResNet-50\": \"resnet\"\n",
    "}\n",
    "\n",
    "vl_models = [\"PLIP\", \"QuiltNet\", \"CONCH\", \"KEEP\", \"MUSK\"]\n",
    "\n",
    "embedding_dir = \"/lotterlab/users/vmishra\"\n",
    "\n",
    "embeddings = {}\n",
    "\n",
    "for model_name in models:\n",
    "    model_key = model_file_keys[model_name]\n",
    "    embeddings_list = []\n",
    "\n",
    "    print(f\"\\nProcessing {model_name}...\")\n",
    "    for subtype in subtypes:\n",
    "        file_path = os.path.join(embedding_dir, f\"{subtype}_embeddings_{model_key}_normalized.npy\")\n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"Missing: {file_path}\")\n",
    "            continue\n",
    "\n",
    "        emb = np.load(file_path)\n",
    "        embeddings_list.append(emb)\n",
    "\n",
    "    if len(embeddings_list) < 4:\n",
    "        print(f\"Skipping {model_name} due to missing data.\")\n",
    "        continue\n",
    "\n",
    "    embeddings[model_name] = np.concatenate(embeddings_list, axis=0)\n",
    "    embeddings[model_name] -= embeddings[model_name].mean(axis=0)\n",
    "\n",
    "spectra = {}\n",
    "for model_name in models:\n",
    "    print(model_name)\n",
    "    U, S, Vt = np.linalg.svd(embeddings[model_name], full_matrices=False)\n",
    "    normalized_spectrum = S / S.sum()\n",
    "    spectra[model_name] = normalized_spectrum\n",
    "\n",
    "for model_name in models:\n",
    "    print(model_name, embeddings[model_name].shape)\n",
    "\n",
    "normalized_spectrum.sum(axis=-1)\n",
    "\n",
    "p_test = [0.25] + list(range(1, 101))\n",
    "s_sums = np.zeros((len(models), len(p_test)))\n",
    "for i, m in enumerate(models):\n",
    "    n_feat = embeddings[m].shape[-1]\n",
    "    for j, p in enumerate(p_test):\n",
    "        cut_off = int(np.round(n_feat * p/100))\n",
    "        s_sums[i, j] = spectra[m][:(cut_off+1)].sum()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for i, m in enumerate(models):\n",
    "    line_style = '--' if m in vl_models else '-'\n",
    "    plt.plot(p_test, s_sums[i], label=m, linewidth=2, linestyle=line_style)\n",
    "\n",
    "plt.legend(prop={'weight':'bold', 'size': 11})\n",
    "ax.set_ylim([0, 1.02])\n",
    "ax.set_aspect(100, adjustable='box')\n",
    "plt.xlabel('Percentage of Features', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Singular Value Cumulative Sum', fontsize=12, fontweight='bold')\n",
    "plt.title('SVD Spectral Analysis (Normalized Embeddings)', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Remove top and right spines\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "plt.savefig('spectral_analysis_normalized.pdf', dpi=300, bbox_inches='tight', pad_inches=0.05)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
